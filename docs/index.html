<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
<!-- Start : Google Analytics Code -->
<!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-64069893-2', 'auto');
  ga('send', 'pageview');
</script> -->
<!-- End : Google Analytics Code -->
<script type="text/javascript" src="resources/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <head>
    <link rel="icon" type="image/png" href="resources/ucsd_logo.png">
    <title>AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition</title>
    <meta property='og:title' content='AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition' />
    <meta property="og:description" content="Meng, Panda, Lin, Sattigeri, Karlinsky, Oliva, Saenko, Feris. AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition. In ICLR, 2021." />
    <meta property='og:url' content='https://mengyuest.github.io/AdFuse/' />
  </head>

  <body>
        <br>
        <center><span style="font-size:40px;font-weight:bold;color:#182B49">AdaFuse: Adaptive Temporal Fusion Network for <br/> Efficient Action Recognition</span></center>

        <table align=center width=900px>
          <tr>
            <td align=center width=180px>
            <center><span style="font-size:24px"><a href="https://mengyuest.github.io/" target="_blank">Yue
            Meng</a><sup>&#8225</sup></span></center></td>
            <td align=center width=180px>
                <center><span style="font-size:24px"><a href="https://rpand002.github.io/" target="_blank">Rameswar Panda</a><sup>&#x2666</sup><sup>&#9839</sup></span></center></td>
            <td align=center width=180px>
            <center><span style="font-size:24px"><a href="https://www.linkedin.com/in/chung-ching-lin-29b05026/" target="_blank">Chung-Ching Lin </a><sup>&#8226</sup></span></center></td>
            <td align=center width=180px>
            <center><span style="font-size:24px"><a href="https://pronics2004.github.io/" target="_blank">Prasanna Sattigeri</a><sup>&#9839</sup></span></center></td>
          <tr/>
         </table>

         <table align=center width=800px>
            <tr>
        <td align=center width=150px>
            <center><span style="font-size:24px"><a href="https://researcher.watson.ibm.com/researcher/view.php?person=il-LEONIDKA" target="_blank"> Leonid Karlinsky</a><sup>&#9839</sup></span></center></td>
        <td align=center width=150px>
            <center><span style="font-size:24px"><a href="http://ai.bu.edu/ksaenko.html" target="_blank">Kate Saenko</a><sup>&#167</sup><sup>&#x2666</sup></span></center></td>
        <td align=center width=150px>
            <center><span style="font-size:24px"><a href="http://olivalab.mit.edu/audeoliva.html" target="_blank">Aude Oliva</a><sup>&#8225</sup><sup>&#x2666</sup></span></center></td>
        <td align=center width=150px>
            <center><span style="font-size:24px"><a href="http://rogerioferis.com/" target="_blank">Rogerio Feris</a><sup>&#x2666</sup><sup>&#9839</sup></span></center></td>
        <tr/>
      </table>

        <table align=center width=800px>
          <tr>
            <td align=center width=700px><center><span style="font-size:24px">Massachusetts Institute of Technology<sup>&#8225</sup></span></center></td>
            <tr/>
          <tr>
            <td align=center width=700px><center><span style="font-size:24px">MIT-IBM Watson AI Lab<sup>&#x2666</sup></span></center></td>
          <tr/>
          <tr>
            <td align=center width=700px><center><span style="font-size:24px">IBM Research<sup>&#9839</sup></span></center></td>
          <tr/>
          <tr>
            <td align=center width=700px><center><span style="font-size:24px">Microsoft Research<sup>&#8226</sup></span></center></td>
          <tr/>
            <tr>
            <td align=center width=700px><center><span style="font-size:24px">Boston University<sup>&#167</sup></span></center></td>
            <tr/>


        </table>
        <table align=center width=400px>
          <tr>
            <td align=center width=150px>
            <center><span style="font-size:24px"><a href="https://openreview.net/group?id=ICLR.cc/2021/Conference" target="_blank">ICLR 2021</a></span></center></td>
          <tr/>
        </table>
        <table align=center width=900px>
            <tr><td width=900px>
              <center><a href="resources/network.png"><img src = "resources/1_arch.png" height="250px"></img></a><br></center>
            </td></tr>
        </table>

        <center id="abstract"><h1>Abstract</h1></center>
        Temporal modelling is the key for efficient video action recognition. While understanding temporal information can improve recognition accuracy for dynamic actions, removing temporal redundancy and reusing past features can significantly save computation leading to efficient action recognition. In this paper, we introduce an adaptive temporal fusion network, called AdaFuse, that dynamically fuses channels from current and past feature maps for strong temporal modelling. Specifically, the necessary information from the historical convolution feature maps is fused with current pruned feature maps with the goal of improving both recognition accuracy and efficiency. In addition, we use a skipping operation to further reduce the computation cost of action recognition. Extensive experiments on SomethingV1 & V2, Jester and Mini-Kinetics show that our approach can achieve about 40% computation savings with comparable accuracy to state-of-the-art methods.
        <br>
        <hr>


        <center id="results0"><h1>Action recognition results on SomethingSomethingV1 & V2</h1></center>
        <table align=center width=1000px>
            <tr><td width=500px>
              <center><a href="resources/table.png"><img src = "resources/2_table.png" height="320px"></img></a><br></center>
            </td></tr>
          </table>
        <br>
        <hr>

        <center id="results1"><h1>Accuracy versus efficiency comparison</h1></center>
        <table align=center width=1000px>
            <tr><td width=500px>
              <center><a href="resources/graph.png"><img src = "resources/3_curve.png" height="400px"></img></a><br></center>
            </td></tr>
          </table>

        <br>
        <hr>

        <center id="results1"><h1>Dataset-specific policy distribution</h1></center>
        <table align=center width=1000px>
            <tr><td width=500px>
              <center><a href="resources/graph.png"><img src = "resources/4_pie.png" height="400px"></img></a><br></center>
            </td></tr>
          </table>

        <br>
        <hr>

        <center id="results1"><h1>Policy distribution and trends for eachresidual block</h1></center>
        <table align=center width=1000px>
            <tr><td width=500px>
              <center><a href="resources/graph.png"><img src = "resources/5_bar.png" height="400px"></img></a><br></center>
            </td></tr>
          </table>

        <br>
        <hr>
        
        <center id="sourceCode"><h1>Paper and Code</h1></center>


        <table align=center width=900px>
            <tr></tr>
          <tr>
            <td >
        <a href="https://github.com/mengyuest/AdaFuse"><img class="paperpreview" src="resources/1_arch.png" width="200px"/></a>
          </td>
          <td></td>
          <td width=700px > <span style="font-size:20px">
              Yue Meng, Rameswar Panda, Chung-Ching Lin, Prasanna Sattigeri, Leonid Karlinsky, Kate Saenko, Aude Oliva, and Rogerio Feris. <br/> <a href="https://mengyuest.github.io/AdaFuse">AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition</a> <br/> <i>International Conference on Learning Representations (ICLR)</i>, 2021 <br/>[<a href="https://arxiv.org/pdf/2102.05775.pdf">PDF</a>][<a href="https://github.com/mengyuest/AdaFuse">Code</a>]</span>
        </td>
        </tr>

      </table>

      <br>
      <hr>

      <br/>

    <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>
</html>
